import requests
import time
import os
import subprocess
from datetime import datetime
from typing import Optional, Dict, List
from datetime import datetime, timedelta
from Config.config import (
    VIDEO_INDEXER_ACCOUNT_ID,
    VIDEO_INDEXER_LOCATION,
    VIDEO_INDEXER_SUB_ID,
    VIDEO_INDEXER_RG,
    VIDEO_INDEXER_VI_ACC,
)
from dotenv import load_dotenv
from VideoIndexerClient.VideoIndexerClient import VideoIndexerClient
from VideoIndexerClient.Consts import Consts
from Source.Services.blob_manager import BlobManager
from Config.logging_config import setup_logging

logger = setup_logging()
class VideoIndexerManager:
    """
    ×× ×”×œ ×¢×™×‘×•×“ ×•×™×“××• ×‘×××¦×¢×•×ª Azure Video Indexer
    ××ª××—×” ×‘×¢×™×‘×•×“ ×•×™×“××• ×-blob storage ×•×™×¦×™×¨×ª ×§×‘×¦×™ markdown
    """

    def __init__(self):
        self.account_id = VIDEO_INDEXER_ACCOUNT_ID
        self.location = VIDEO_INDEXER_LOCATION
        self.subscription_id = VIDEO_INDEXER_SUB_ID
        self.resource_group = VIDEO_INDEXER_RG
        self.account_name = VIDEO_INDEXER_VI_ACC
        self.supported_formats = ['.mp4', '.avi', '.mov', '.wmv', '.flv', '.webm', '.mkv']

        self._access_token = None
        self._token_expiry = None

        # ×™×¦×™×¨×ª VideoIndexer client ×œ×¨×¢× ×•×Ÿ ××¤×ª×—×•×ª
        self._vi_client = None
        self._consts = None
        self._initialize_vi_client()

    def _initialize_vi_client(self):
        """××ª×—×•×œ VideoIndexer client ×œ×¨×¢× ×•×Ÿ ××¤×ª×—×•×ª"""
        try:
            load_dotenv()

            self._consts = Consts(
                ApiVersion='2024-01-01',
                ApiEndpoint='https://api.videoindexer.ai',
                AzureResourceManager='https://management.azure.com',
                AccountName=self.account_name,
                ResourceGroup=self.resource_group,
                SubscriptionId=self.subscription_id
            )

            self._vi_client = VideoIndexerClient()
            logger.info("âœ… VideoIndexer client ××•×ª×—×œ ×‘×”×¦×œ×—×”")

        except Exception as e:
            logger.info(f"âš ï¸ ×©×’×™××” ×‘××ª×—×•×œ VideoIndexer client: {e}")
            self._vi_client = None

    def get_valid_token(self):
        """×§×‘×œ×ª ××¤×ª×— ×ª×§×£ - ××¨×¢× ×Ÿ ××•×˜×•××˜×™×ª ×× × ×“×¨×©"""
        if self._should_refresh_token():
            self._refresh_token()

        return self._access_token


    def _should_refresh_token(self):
        """×‘×“×™×§×” ×× ×¦×¨×™×š ×œ×¨×¢× ×Ÿ ××ª ×”××¤×ª×—"""
        if not self._access_token:
            return True

        if not self._token_expiry:
            return True

        # ×¨×¢× ×Ÿ 5 ×“×§×•×ª ×œ×¤× ×™ ×¤×§×™×¢×”
        refresh_time = self._token_expiry - timedelta(minutes=5)
        return datetime.utcnow() >= refresh_time

    def _refresh_token(self):
        """×¨×¢× ×•×Ÿ ××¤×ª×— Video Indexer"""
        if not self._vi_client or not self._consts:
            logger.info("âš ï¸ VideoIndexer client ×œ× ×–××™×Ÿ, ××©×ª××© ×‘××¤×ª×— ×§×‘×•×¢")
            return

        try:
            logger.info("ğŸ”„ ××¨×¢× ×Ÿ ××¤×ª×— Video Indexer...")

            # ×§×‘×œ×ª ××¤×ª×—×•×ª ×—×“×©×™×
            arm_token, vi_token, response = self._vi_client.authenticate_async(self._consts)

            if vi_token:
                self._access_token = vi_token

                # ×—×™×œ×•×¥ ×–××Ÿ ×¤×§×™×¢×” ××”××¤×ª×—
                self._extract_token_expiry(vi_token)

                logger.info(f"âœ… ××¤×ª×— ×¨×•×¢× ×Ÿ ×‘×”×¦×œ×—×”. ××•×¨×š: {len(vi_token)}")
                if self._token_expiry:
                    current_time = datetime.utcnow()
                    logger.info(f"ğŸ• ×–××Ÿ × ×•×›×—×™: {current_time}")
                    logger.info(f"â° ×¤×•×§×¢ ×‘: {self._token_expiry}")
            else:
                logger.info("âŒ ×œ× ×”×ª×§×‘×œ ××¤×ª×— ×—×“×©")

        except Exception as e:
            logger.info(f"âŒ ×©×’×™××” ×‘×¨×¢× ×•×Ÿ ××¤×ª×—: {e}")


    def _extract_token_expiry(self, token):
        try:
            # ×‘××§×•× ×œ×¤×¢× ×— ××ª ×”×˜×•×§×Ÿ, ×¤×©×•×˜ × ×’×“×™×¨ ×©×”×•× ×ª×§×£ ×œ×©×¢×” ××¢×›×©×™×•
            self._token_expiry = datetime.utcnow() + timedelta(hours=1)
            logger.info(f"ğŸ“… ×–××Ÿ ×¤×§×™×¢×ª ××¤×ª×— (××©×•×¢×¨): {self._token_expiry}")

        except Exception as e:
            logger.info(f"âš ï¸ ×©×’×™××” ×‘×”×’×“×¨×ª ×–××Ÿ ×¤×§×™×¢×”: {e}")


    def _get_params_with_token(self, additional_params=None):
        """×§×‘×œ×ª ×¤×¨××˜×¨×™× ×¢× ×˜×•×§×Ÿ ×’×™×©×”."""
        token = self.get_valid_token()
        params = {"accessToken": token}
        if additional_params:
            params.update(additional_params)
        return params

    def upload_video_from_url(self, video_sas_url: str, video_name: str) -> str:
        """
        ×”×¢×œ××ª ×•×™×“××• ×œ-Video Indexer ×‘×××¦×¢×•×ª SAS URL

        Args:
            video_sas_url: SAS URL ×©×œ ×”×•×™×“××• ×‘-blob storage
            video_name: ×©× ×”×•×™×“××• ×‘-Video Indexer
        """
        logger.info(f"ğŸ“¤ ××¢×œ×” ×•×™×“××•: {video_name}")

        url = f"https://api.videoindexer.ai/{self.location}/Accounts/{self.account_id}/Videos"

        params = self._get_params_with_token({
            "name": video_name,
            "privacy": "Private",
            "videoUrl": video_sas_url,
            "language": "he-IL",
            "streamingPreset": "NoStreaming",
            "retentionPeriod": "7"
        })

        try:
            logger.info(f"  â³ ×©×•×œ×— ×‘×§×©×” ×œ-Video Indexer...")
            resp = requests.post(url, params=params, timeout=30)
            resp.raise_for_status()

            data = resp.json()
            video_id = data.get("id") or data.get("videoId")

            if not video_id:
                raise RuntimeError(f"×”×¢×œ××” × ×›×©×œ×”: {data}")

            logger.info(f"  âœ… ×”×•×¢×œ×” ×‘×”×¦×œ×—×”, ××–×”×” ×•×™×“××•: {video_id}")
            return video_id

        except requests.exceptions.RequestException as e:
            raise RuntimeError(f"×©×’×™××” ×‘×”×¢×œ××ª ×”×•×™×“××•: {str(e)}")

    def wait_for_indexing(self, video_id: str, interval: int = 10, max_wait_minutes: int = 180) -> Dict:
        """×”××ª× ×” ×œ×¡×™×•× ×¢×™×‘×•×“ ×”×•×™×“××• ×‘-Video Indexer"""
        logger.info(f"â³ ×××ª×™×Ÿ ×œ×¡×™×•× ×¢×™×‘×•×“ ×”×•×™×“××• {video_id}...")

        url = f"https://api.videoindexer.ai/{self.location}/Accounts/{self.account_id}/Videos/{video_id}/Index"
        start_time = time.time()
        max_wait_seconds = max_wait_minutes * 60

        while True:
            try:
                params = self._get_params_with_token()
                resp = requests.get(url, params=params)
                resp.raise_for_status()
                data = resp.json()

                state = data.get("state")
                logger.info(f"  ğŸ“Š ××¦×‘ ×¢×™×‘×•×“: {state}")

                if state == "Processed":
                    logger.info("  âœ… ×¢×™×‘×•×“ ×”×•×©×œ×!")
                    return data
                elif state == "Failed":
                    raise RuntimeError("×¢×™×‘×•×“ ×”×•×™×“××• × ×›×©×œ")

                elapsed_time = time.time() - start_time
                if elapsed_time > max_wait_seconds:
                    raise TimeoutError(f"×¢×™×‘×•×“ ×”×•×™×“××• ×œ×§×— ×™×•×ª×¨ ×-{max_wait_minutes} ×“×§×•×ª")

                time.sleep(interval)

            except requests.exceptions.RequestException as e:
                raise RuntimeError(f"×©×’×™××” ×‘×‘×“×™×§×ª ××¦×‘ ×”×¢×™×‘×•×“: {str(e)}")

    def extract_transcript_with_timestamps(self, index_json: Dict) -> List[Dict]:
        """×—×™×œ×•×¥ ×˜×¨× ×¡×§×¨×™×¤×˜ ×¢× ×—×•×ª××•×ª ×–××Ÿ"""
        transcript_items = (
            index_json
            .get("videos", [{}])[0]
            .get("insights", {})
            .get("transcript", [])
        )

        transcript_segments = []

        for item in transcript_items:
            text = item.get("text", "")
            instances = item.get("instances", [])

            if text and instances:
                first_instance = instances[0]
                start_time = first_instance.get("start", "00:00:00")
                end_time = first_instance.get("end", "00:00:00")

                start_seconds = self._time_to_seconds(start_time)
                end_seconds = self._time_to_seconds(end_time)

                segment = {
                    "text": text,
                    "start_time": start_time,
                    "end_time": end_time,
                    "start_seconds": start_seconds,
                    "end_seconds": end_seconds,
                    "duration": end_seconds - start_seconds,
                    "confidence": item.get("confidence", 0.9)
                }
                transcript_segments.append(segment)

        return transcript_segments

    def merge_segments_by_duration(self, segments: List[Dict], max_duration_seconds: int = 30) -> List[Dict]:
        """××™×—×•×“ ×¡×’×× ×˜×™× ×œ×¡×’×× ×˜×™× ××¨×•×›×™× ×™×•×ª×¨"""
        if not segments:
            return []

        merged_segments = []
        current_segment = None

        for segment in segments:
            if current_segment is None:
                current_segment = {
                    "text": segment["text"],
                    "start_time": segment["start_time"],
                    "end_time": segment["end_time"],
                    "start_seconds": segment["start_seconds"],
                    "end_seconds": segment["end_seconds"],
                    "duration": segment["duration"],
                    "confidence": segment["confidence"]
                }
            else:
                potential_duration = segment["end_seconds"] - current_segment["start_seconds"]

                if potential_duration <= max_duration_seconds:
                    current_segment["text"] += " " + segment["text"]
                    current_segment["end_time"] = segment["end_time"]
                    current_segment["end_seconds"] = segment["end_seconds"]
                    current_segment["duration"] = current_segment["end_seconds"] - current_segment["start_seconds"]
                    current_segment["confidence"] = (current_segment["confidence"] + segment["confidence"]) / 2
                else:
                    merged_segments.append(current_segment)
                    current_segment = {
                        "text": segment["text"],
                        "start_time": segment["start_time"],
                        "end_time": segment["end_time"],
                        "start_seconds": segment["start_seconds"],
                        "end_seconds": segment["end_seconds"],
                        "duration": segment["duration"],
                        "confidence": segment["confidence"]
                    }

        if current_segment is not None:
            merged_segments.append(current_segment)

        logger.info(f"  ğŸ”— ××™×—×•×“ ×¡×’×× ×˜×™×: {len(segments)} â†’ {len(merged_segments)} (××§×¡ {max_duration_seconds} ×©× ×™×•×ª)")
        return merged_segments

    def create_textual_summary(self, video_id: str, deployment_name: str = "gpt-4o") -> str:
        """×™×¦×™×¨×ª ×¡×™×›×•× ×˜×§×¡×˜×•××œ×™ ×‘×××¦×¢×•×ª GPT"""
        url = f"https://api.videoindexer.ai/{self.location}/Accounts/{self.account_id}/Videos/{video_id}/Summaries/Textual"
        params = self._get_params_with_token({
            "deploymentName": deployment_name,
            "length": "Long",
            "style": "Formal",
            "includedFrames": "All",
            "addToEndOfSummaryInstructions": "×›×ª×•×‘ ×¡×™×›×•× ××¤×•×¨×˜ ×©×œ ×”×©×™×¢×•×¨ ×‘×¢×‘×¨×™×ª. ×”×¦×’ ××ª ×”×—×•××¨ ×‘×¡×“×¨ ×”×›×¨×•× ×•×œ×•×’×™ ×©×‘×• × ×œ××“. ×œ×›×œ × ×•×©× ××¨×›×–×™, ×ª×Ÿ ×”×’×“×¨×•×ª ×‘×¨×•×¨×•×ª ×œ××•× ×—×™× ×—×“×©×™× ×•×”×¡×‘×¨ ××ª ×”× ×§×•×“×” ×”××¨×›×–×™×ª ×‘××©×¤×˜ ××—×“. ×›×ª×•×‘ ×‘×˜×•×Ÿ ×¤×“×’×•×’×™ ×›×š ×©×¡×˜×•×“× ×˜ ×™×•×›×œ ×œ×©×œ×•×˜ ×‘×—×•××¨ ××”×¡×™×›×•× ×œ×‘×“×•. ×¡×™×™× ×‘×¨×©×™××ª ×¤×¢×•×œ×•×ª ×§×•× ×§×¨×˜×™×•×ª ××• ×”××œ×¦×•×ª ×œ×™××•×“ ×œ×¡×˜×•×“× ×˜×™×. ×‘×¡×•×£ ×”×•×¡×£ ×©×•×¨×” ××—×ª ×¢× ××™×œ×” ××—×ª ×‘×œ×‘×“: '××ª××˜×™' ××• '×”×•×× ×™' ×›×“×™ ×œ×¡×•×•×’ ×× ×–×” ×§×•×¨×¡ ××ª××˜×™ ××• ×”×•×× ×™."
        })

        try:
            resp = requests.post(url, params=params, timeout=30)
            resp.raise_for_status()
            summary_id = resp.json().get("id")
            if not summary_id:
                raise RuntimeError(f"×™×¦×™×¨×ª ×¡×™×›×•× × ×›×©×œ×”: {resp.text}")
            logger.info(f"  âœ… × ×•×¦×¨ ×¡×™×›×•× ×¢× ××–×”×”: {summary_id}")
            return summary_id
        except requests.exceptions.HTTPError as e:
            if e.response.status_code == 400:
                logger.info(f"  âš ï¸ ×™×¦×™×¨×ª ×¡×™×›×•× GPT × ×›×©×œ×” (400 Bad Request)")
                logger.info(f"  âš ï¸ ×™×¦×™×¨×ª ×¡×™×›×•× GPT × ×›×©×œ×” (400 Bad Request)")
                logger.info(f"  ğŸ“ ×ª×’×•×‘×”: {e.response.text}")
                raise RuntimeError(f"×¡×™×›×•× GPT ×œ× ×–××™×Ÿ: {e.response.text}")
            else:
                raise

    def get_textual_summary(self, video_id: str, summary_id: str) -> str:
        """×§×‘×œ×ª ×”×¡×™×›×•× ×”×˜×§×¡×˜×•××œ×™ ×œ××—×¨ ×©×”×•× ××•×›×Ÿ"""
        url = f"https://api.videoindexer.ai/{self.location}/Accounts/{self.account_id}/Videos/{video_id}/Summaries/Textual/{summary_id}"

        while True:
            params = self._get_params_with_token()
            resp = requests.get(url, params=params, timeout=15)
            resp.raise_for_status()
            data = resp.json()
            state = data.get("state")
            if state == "Processed":
                summary = data.get("summary", "")
                logger.info(f"  âœ… ×”×¡×™×›×•× ××•×›×Ÿ. ××•×¨×š: {len(summary)} ×ª×•×•×™×")
                return summary
            elif state == "Failed":
                raise RuntimeError(f"×™×¦×™×¨×ª ×”×¡×™×›×•× × ×›×©×œ×”: {data}")
            else:
                logger.info(f"  â³ ××¦×‘ ×”×¡×™×›×•×: {state} â€” ×××ª×™×Ÿ...")
                time.sleep(10)

    def delete_video(self, video_id: str) -> bool:
        """××—×™×§×ª ×•×™×“××• ×-Video Indexer ×›×“×™ ×œ× ×§×•×ª ×§×•× ×˜×™×™× ×¨×™× ××™×•×ª×¨×™×"""
        url = f"https://api.videoindexer.ai/{self.location}/Accounts/{self.account_id}/Videos/{video_id}"

        try:
            params = self._get_params_with_token()
            resp = requests.delete(url, params=params, timeout=30)
            resp.raise_for_status()

            logger.info(f"  ğŸ—‘ï¸ ×”×•×™×“××• × ××—×§ ×-Video Indexer: {video_id}")
            return True

        except requests.exceptions.RequestException as e:
            logger.info(f"  âš ï¸ ×©×’×™××” ×‘××—×™×§×ª ×”×•×™×“××• ×-Video Indexer: {str(e)}")
            return False

    def extract_video_metadata(self, index_json: Dict) -> Dict:
        """×—×™×œ×•×¥ ××˜×-×“××˜×” ××”×•×™×“××•"""
        vid_info = index_json.get('videos', [{}])[0]
        insights = vid_info.get('insights', {})

        # ××©×š ×–××Ÿ
        duration_sec = vid_info.get('durationInSeconds', 0)
        if not duration_sec:
            duration_obj = insights.get('duration')
            if isinstance(duration_obj, dict):
                duration_sec = duration_obj.get('time', 0)
            elif isinstance(duration_obj, str):
                duration_sec = self._time_to_seconds(duration_obj)
            else:
                duration_sec = insights.get('durationInSeconds', 0)

        # ××™×œ×•×ª ××¤×ª×— ×•× ×•×©××™×
        keywords = [kw.get('text') for kw in insights.get('keywords', []) if kw.get('text')]
        topics = [tp.get('name') for tp in insights.get('topics', []) if tp.get('name')]

        # OCR
        ocr_texts = []
        if 'ocr' in insights:
            ocr_texts = [o.get('text') for o in insights.get('ocr', []) if o.get('text')]

        # ×“×•×‘×¨×™×
        speakers = []
        if 'speakers' in insights:
            speakers = [s.get('name') for s in insights.get('speakers', []) if s.get('name')]
        if not speakers and 'speakers' in insights:
            speakers = [f"×“×•×‘×¨ #{s.get('id', i + 1)}" for i, s in enumerate(insights.get('speakers', []))]

        metadata = {
            'video_id': index_json.get('id', ''),
            'name': vid_info.get('name', ''),
            'description': index_json.get('description', ''),
            'duration': self._seconds_to_hhmmss(int(duration_sec)) if duration_sec else '×œ× ×–××™×Ÿ',
            'language': insights.get('sourceLanguage', 'he-IL'),
            'keywords': keywords,
            'topics': topics,
            'ocr': ocr_texts,
            'speakers': speakers if speakers else ['××¨×¦×”'],
            'created_date': datetime.now().isoformat()
        }

        logger.info(f"  ğŸ“Š ×—×•×œ×¥ ××˜×-×“××˜×”:")
        logger.info(f"    - ××©×š ×–××Ÿ: {metadata['duration']}")
        logger.info(f"    - ××™×œ×•×ª ××¤×ª×—: {len(keywords)} × ××¦××•")
        logger.info(f"    - × ×•×©××™×: {len(topics)} × ××¦××•")
        logger.info(f"    - ×˜×§×¡×˜×™ OCR: {len(ocr_texts)} × ××¦××•")

        return metadata

    def _time_to_seconds(self, time_str: str) -> int:
        """×”××¨×ª ×–××Ÿ ×œ×©× ×™×•×ª"""
        try:
            if ':' in time_str:
                parts = time_str.split(':')
                if len(parts) == 3:  # HH:MM:SS
                    hours, minutes, seconds = map(float, parts)
                    return int(hours * 3600 + minutes * 60 + seconds)
                elif len(parts) == 2:  # MM:SS
                    minutes, seconds = map(float, parts)
                    return int(minutes * 60 + seconds)
            return int(float(time_str))
        except:
            return 0

    def _seconds_to_hhmmss(self, seconds: int) -> str:
        """×”××¨×ª ×©× ×™×•×ª ×œ×¤×•×¨××˜ HH:MM:SS"""
        hours = seconds // 3600
        minutes = (seconds % 3600) // 60
        secs = seconds % 60
        return f"{hours:02d}:{minutes:02d}:{secs:02d}"

    def parse_insights_to_md(self, structured_data: Dict) -> str:
        """×”××¨×ª × ×ª×•× ×™ ×”×•×™×“××• ×œ×¤×•×¨××˜ Markdown"""
        md_content = []

        # ×›×•×ª×¨×ª ×¨××©×™×ª
        md_content.append(f"# {structured_data.get('name', '×“×•×— × ×™×ª×•×— ×•×™×“××•')}")
        md_content.append("")

        # ××˜×-×“××˜×”
        md_content.append("## ğŸ“Š ×¤×¨×˜×™ ×”×•×™×“××•")
        md_content.append(f"- **××–×”×” ×•×™×“××•**: {structured_data.get('id', '×œ× ×–××™×Ÿ')}")
        md_content.append(f"- **××©×š ×–××Ÿ**: {structured_data.get('duration', '×œ× ×–××™×Ÿ')}")
        md_content.append(f"- **×©×¤×”**: {structured_data.get('language', '×œ× ×–××™×Ÿ')}")
        md_content.append(f"- **×“×•×‘×¨×™×**: {', '.join(structured_data.get('speakers', []))}")
        md_content.append(f"- **×ª××¨×™×š ×™×¦×™×¨×”**: {structured_data.get('created_date', '×œ× ×–××™×Ÿ')}")
        md_content.append("")

        # ××™×œ×•×ª ××¤×ª×—
        keywords = structured_data.get('keywords', [])
        if keywords:
            md_content.append("## ğŸ” ××™×œ×•×ª ××¤×ª×—")
            md_content.append(", ".join(f"`{kw}`" for kw in keywords))
            md_content.append("")

        # × ×•×©××™×
        topics = structured_data.get('topics', [])
        if topics:
            md_content.append("## ğŸ·ï¸ × ×•×©××™×")
            md_content.append(", ".join(f"`{topic}`" for topic in topics))
            md_content.append("")

        # OCR
        ocr_texts = structured_data.get('ocr', [])
        if ocr_texts:
            md_content.append("## ğŸ‘ï¸ ×˜×§×¡×˜ ×©×—×•×œ×¥ ××”×•×™×“××• (OCR)")
            for i, ocr_text in enumerate(ocr_texts, 1):
                md_content.append(f"{i}. {ocr_text}")
            md_content.append("")

        # ×¡×™×›×•× ×”×©×™×¢×•×¨
        summary_text = structured_data.get('summary_text', '')
        if summary_text:
            # ×—×™×œ×•×¥ ×¡×•×’ ×”××§×¦×•×¢ ××”×¡×™×›×•×
            subject_type = "×œ× ×–×•×”×”"
            summary_lines = summary_text.strip().split('\n')
            last_line = summary_lines[-1].strip() if summary_lines else ""

            if last_line in ['××ª××˜×™', '×”×•×× ×™']:
                subject_type = last_line
                # ×”×¡×¨×ª ×”×©×•×¨×” ×”××—×¨×•× ×” ××”×¡×™×›×•×
                summary_text = '\n'.join(summary_lines[:-1]).strip()

            # ×”×•×¡×¤×ª ×¡×•×’ ×”××§×¦×•×¢
            md_content.append(f"## ğŸ“ ×¡×•×’ ××§×¦×•×¢")
            md_content.append(subject_type)
            md_content.append("")

            # ×”×•×¡×¤×ª ×”×¡×™×›×•×
            md_content.append("## ğŸ“ ×¡×™×›×•× ×”×©×™×¢×•×¨")
            md_content.append(summary_text)
            md_content.append("")

        # ×ª×™××•×¨
        if structured_data.get('description'):
            md_content.append("## ğŸ“ ×ª×™××•×¨")
            md_content.append(structured_data['description'])
            md_content.append("")

        # ×˜×¨× ×¡×§×¨×™×¤×˜ ××œ×
        md_content.append("## ğŸ“„ ×˜×¨× ×¡×§×¨×™×¤×˜ ××œ×")
        md_content.append(structured_data.get('full_transcript', '×˜×¨× ×¡×§×¨×™×¤×˜ ×œ× ×–××™×Ÿ'))
        md_content.append("")

        # ×˜×¨× ×¡×§×¨×™×¤×˜ ×¢× ×—×•×ª××•×ª ×–××Ÿ
        transcript_segments = structured_data.get('transcript_segments', [])
        if transcript_segments:
            md_content.append("## â° ×˜×¨× ×¡×§×¨×™×¤×˜ ×¢× ×—×•×ª××•×ª ×–××Ÿ")
            md_content.append("")

            for segment in transcript_segments:
                start_time = segment.get('start_time', '00:00:00')
                text = segment.get('text', '')
                md_content.append(f"**[{start_time}]** {text}")
                md_content.append("")

        return "\n".join(md_content)


    def process_video_to_md(self, course_id: str, section_id: str, file_id: int, video_name: str, video_url: str, merge_segments_duration: Optional[int] = 30) -> str | None:
        """
        ×¢×™×‘×•×“ ×•×™×“××• ×-blob storage ×œ×™×¦×™×¨×ª ×§×•×‘×¥ markdown

        Args:
            course_id: ××–×”×” ×”×§×•×¨×¡
            section_id: ××–×”×” ×”×¡×§×¦×™×”
            file_id: ××–×”×” ×”×§×•×‘×¥
            video_name: ×©× ×”×•×™×“××• (×™×™×›× ×¡ ×œ×ª××œ×•×œ)
            video_url: × ×ª×™×‘ ×”×•×™×“××• ×‘-blob storage
            merge_segments_duration: ××©×š ×–××Ÿ ××§×¡×™××œ×™ ×‘×©× ×™×•×ª ×œ××™×—×•×“ ×¡×’×× ×˜×™×

        Returns:
            × ×ª×™×‘ ×”×§×•×‘×¥ ×‘-blob storage ××• None ×× × ×›×©×œ
        """
        # ×™×¦×™×¨×ª ×× ×”×œ×™ blob - ××—×“ ×œ×§×¨×™××” ×-raw-data ×•××—×“ ×œ×›×ª×™×‘×” ×œ-processeddata
        blob_manager_read = BlobManager(container_name="raw-data")
        blob_manager_write = BlobManager(container_name="processeddata")

        # ×‘×“×™×§×ª ×¡×™×•××ª ×”×§×•×‘×¥
        file_ext = os.path.splitext(video_url)[1].lower()
        if file_ext not in self.supported_formats:
            logger.info(f"âŒ ×¤×•×¨××˜ ×•×™×“××• ×œ× × ×ª××š: {video_url}")
            return None

        # ×™×¦×™×¨×ª SAS URL ×œ×•×™×“××• ××§×•× ×˜×™×™× ×¨ raw-data
        logger.info(f"ğŸ”— ×™×•×¦×¨ SAS URL ×œ×•×™×“××• ××§×•× ×˜×™×™× ×¨ raw-data: {video_url}")
        video_sas_url = blob_manager_read.generate_sas_url(video_url, hours=4)

        if not video_sas_url:
            logger.info(f"âŒ × ×›×©×œ×” ×™×¦×™×¨×ª SAS URL ×œ×•×™×“××•: {video_url}")
            return None

        logger.info(f"ğŸ”„ ××¢×‘×“ ×•×™×“××•: {video_name}")

        try:
            logger.info(f"\nğŸ¬ ××ª×—×™×œ ×¢×™×‘×•×“ ×•×™×“××• ×œ-MD: {video_name}")

            # ×”×¢×œ××” ×•×¢×™×‘×•×“ ×œ-Video Indexer ×¢× ×©× ×”×•×™×“××•
            video_id = self.upload_video_from_url(video_sas_url, video_name)
            index_data = self.wait_for_indexing(video_id)

            # ×™×¦×™×¨×ª ×¡×™×›×•× GPT
            logger.info("  ğŸ“ ×™×•×¦×¨ ×¡×™×›×•× GPT...")
            summary_text = ""
            try:
                summary_id = self.create_textual_summary(video_id)
                summary_text = self.get_textual_summary(video_id, summary_id)
                logger.info(f"  âœ… ×”×ª×§×‘×œ ×¡×™×›×•× ×‘××•×¨×š: {len(summary_text)} ×ª×•×•×™×")
            except Exception as e:
                logger.info(f"  âš ï¸ ×™×¦×™×¨×ª ×¡×™×›×•× GPT × ×›×©×œ×”, ×××©×™×š ×‘×œ×™ ×¡×™×›×•×: {e}")

            # ×—×™×œ×•×¥ ×˜×¨× ×¡×§×¨×™×¤×˜
            transcript_segments = self.extract_transcript_with_timestamps(index_data)

            # ××™×—×•×“ ×¡×’×× ×˜×™× ×× × ×“×¨×©
            if merge_segments_duration:
                logger.info(f"  ğŸ”— ×××—×“ ×¡×’×× ×˜×™× ×œ××§×¡×™××•× {merge_segments_duration} ×©× ×™×•×ª...")
                transcript_segments = self.merge_segments_by_duration(transcript_segments, merge_segments_duration)

            # ×—×™×œ×•×¥ ××˜×-×“××˜×”
            metadata = self.extract_video_metadata(index_data)

            # ×™×¦×™×¨×ª ××‘× ×” × ×ª×•× ×™× ××•×‘× ×” ×¢× ×©× ×”×•×™×“××•
            structured_data = {
                "id": str(file_id),  # ×©×™××•×© ×‘-file_id ×›××–×”×” ×‘××§×•× video_id
                "name": video_name,  # ×©×™××•×© ×‘×©× ×©×”×•×¢×‘×¨
                **metadata,
                "transcript_segments": transcript_segments,
                "full_transcript": " ".join([seg["text"] for seg in transcript_segments]),
                "segment_start_times": [seg["start_time"] for seg in transcript_segments],
                "segment_start_seconds": [seg["start_seconds"] for seg in transcript_segments],
                "summary_text": summary_text
            }

            # ×”××¨×” ×œ-markdown
            md_content = self.parse_insights_to_md(structured_data)

            logger.info(f"  âœ… ×¢×™×‘×•×“ ×”×•×©×œ× ×‘×”×¦×œ×—×”!")
            logger.info(f"  ğŸ“Š × ××¦××• {len(transcript_segments)} ×§×˜×¢×™ ×˜×¨× ×¡×§×¨×™×¤×˜")

        except Exception as e:
            logger.info(f"âŒ × ×›×©×œ ×¢×™×‘×•×“ ×”×•×™×“××•: {str(e)}")
            return None

        # ×™×¦×™×¨×ª × ×ª×™×‘ ×”×™×¢×“ ×œ×¤×™ ×”××‘× ×”: CourseID/SectionID/Videos_md/FileID.md
        target_blob_path = f"{course_id}/{section_id}/Videos_md/{file_id}.md"

        logger.info(f"ğŸ“¤ ××¢×œ×” ×œ×§×•× ×˜×™×™× ×¨ processeddata: {target_blob_path}")

        # ×©××™×¨×” ×œ×§×•× ×˜×™×™× ×¨ processeddata
        success = blob_manager_write.upload_text_to_blob(
            text_content=md_content,
            blob_name=target_blob_path
        )

        if success:
            logger.info(f"âœ… ×”×§×•×‘×¥ ×”×•×¢×œ×” ×‘×”×¦×œ×—×” ×œ×§×•× ×˜×™×™× ×¨ processeddata: {target_blob_path}")

            # × ×™×§×•×™: ××—×™×§×ª ×”×•×™×“××• ×-Video Indexer ×›×“×™ ×œ× ×§×•×ª ×§×•× ×˜×™×™× ×¨×™× ××™×•×ª×¨×™×
            logger.info("ğŸ§¹ ×× ×§×” ×§×•× ×˜×™×™× ×¨×™× ××™×•×ª×¨×™×...")
            self.delete_video(video_id)

            return target_blob_path
        else:
            logger.info(f"âŒ × ×›×©×œ×” ×”×¢×œ××ª ×”×§×•×‘×¥ ×œ×§×•× ×˜×™×™× ×¨ processeddata")
            return None


if __name__ == "__main__":
    # ×¢×™×‘×•×“ ×•×™×“××• ×-blob storage ×¢× ×¤×¨××˜×¨×™× ×—×“×©×™×
    course_id = "Information_systems"
    section_id = "Section1"
    file_id = 11122
    video_name = "L1 - A "
    video_url = "L_A_Information_system.mp4"


    logger.info(f"ğŸ§ª ××¢×‘×“ ×•×™×“××•: {video_name}")
    logger.info(f"ğŸ“ CourseID: {course_id}, SectionID: {section_id}, FileID: {file_id}")
    logger.info(f"ğŸ”— VideoURL: {video_url}")

    try:
        manager = VideoIndexerManager()
        result = manager.process_video_to_md(course_id, section_id, file_id, video_name, video_url, merge_segments_duration=20)

        if result:
            logger.info(f"\nğŸ‰ ×”×•×™×“××• ×¢×•×‘×“ ×‘×”×¦×œ×—×”: {result}")
            logger.info(f"ğŸ“ ×”×§×•×‘×¥ × ×©××¨ ×‘××‘× ×”: {course_id}/{section_id}/Videos_md/{file_id}.md")
        else:
            logger.info(f"\nâŒ × ×›×©×œ ×¢×™×‘×•×“ ×”×•×™×“××•: {video_name}")

    except Exception as e:
        logger.info(f"âŒ ×©×’×™××” ×‘×¢×™×‘×•×“ ×”×•×™×“××•: {e}")
